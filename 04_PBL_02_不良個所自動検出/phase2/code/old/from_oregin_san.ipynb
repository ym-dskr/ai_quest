{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"001_FineTune_sample.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"NUW4SqNHYvKG"},"source":["# Google colab の実行時間\n","!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 / 60 / 60 \"h)\"}'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LE4exV97dsMK"},"source":["# Google Driveに接続する。\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IL1hFqcA7ixQ"},"source":["# 初期設定"]},{"cell_type":"code","metadata":{"id":"qSERXHp6r69p"},"source":["# train.zip,test.zipを保存しているフォルダを設定\n","# ※ご自身のデータ保存するフォルダを指定\n","inputpath = '/content/drive/MyDrive/input'\n","\n","# 提出ファイルを保存するフォルダを設定\n","# ※ご自身のデータ保存するフォルダを指定\n","outputpath = '/content/drive/MyDrive/output'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nTOdLQtXy7j3"},"source":["# 学習の回数（エポック数）を設定\n","# ※大きい値ほど学習を繰り返して精度が上がりますが、その分時間がかかります。\n","N_EPOCHS = 3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2aAJxksk8TCz"},"source":["# パッケージのインポート"]},{"cell_type":"code","metadata":{"id":"1gEyCZS4-eq2"},"source":["import glob\n","import os.path as osp\n","import random\n","import numpy as np\n","import pandas\n","import json\n","from PIL import Image\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as data\n","import torchvision\n","from torchvision import models, transforms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wG3lq6Y99HNS"},"source":["# 乱数のシードを設定\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8objs1Fv73tn"},"source":["# データの解凍"]},{"cell_type":"code","metadata":{"id":"d25432qJs0dW"},"source":["!unzip {inputpath}/test.zip\n","!unzip {inputpath}/train.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cc93nHoa9HNb"},"source":["# DatasetとDataLoaderを作成"]},{"cell_type":"code","metadata":{"id":"AK5qh65_9uDC"},"source":["# 入力画像の前処理をするクラス\n","# 訓練時と推論時で処理が異なる\n","\n","class ImageTransform():\n","    \"\"\"\n","    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n","    画像のサイズをリサイズし、色を標準化する。\n","    訓練時はRandomResizedCrop（画像を切り抜き）と\n","    RandomHorizontalFlip（水平反転）で\n","    データオーギュメンテーション（データの水増し）する。\n","\n","    Attributes\n","    ----------\n","    resize : int\n","        リサイズ先の画像の大きさ。\n","    mean : (R, G, B)\n","        各色チャネルの平均値。\n","    std : (R, G, B)\n","        各色チャネルの標準偏差。\n","    \"\"\"\n","    def __init__(self, resize, mean, std):\n","        self.data_transform = {\n","            'train': transforms.Compose([\n","                transforms.RandomResizedCrop(\n","                    resize, scale=(0.5, 1.0)),  # 切り抜きで水増し\n","                transforms.RandomHorizontalFlip(),  #　水平反転で水増し \n","                transforms.ToTensor(),  # テンソルに変換\n","                transforms.Normalize(mean, std)  # 標準化\n","            ]),\n","            'val': transforms.Compose([\n","                transforms.Resize(resize),  # リサイズ\n","                transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\n","                transforms.ToTensor(),  # テンソルに変換\n","                transforms.Normalize(mean, std)  # 標準化\n","            ]),\n","            'test': transforms.Compose([\n","                transforms.Resize(resize),  # リサイズ\n","                transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\n","                transforms.ToTensor(),  # テンソルに変換\n","                transforms.Normalize(mean, std)  # 標準化\n","            ])\n","\n","        }\n","\n","    def __call__(self, img, phase='train'):\n","        \"\"\"\n","        Parameters\n","        ----------\n","        phase : 'train' or 'val'\n","            前処理のモードを指定。\n","        \"\"\"\n","        return self.data_transform[phase](img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lIp16VdJ98wF"},"source":["# 良品と不良品の画像へのファイルパスのリストを作成する\n","\n","def make_datapath_list(phase=\"train\"):\n","    \"\"\"\n","    データのパスを格納したリストを作成する。\n","\n","    Parameters\n","    ----------\n","    phase : 'train' or 'test'\n","        訓練データかテストデータかを指定する\n","\n","    Returns\n","    -------\n","    path_list : list\n","        データへのパスを格納したリスト\n","    \"\"\"\n","\n","    rootpath = \"./\"\n","    if phase == 'test':\n","      target_path = osp.join(rootpath+phase+'/*.jpeg')\n","    else:\n","      target_path = osp.join(rootpath+'/train/**/*.jpeg')  \n","    #print(target_path)\n","\n","    path_list = []  # ここに格納する\n","\n","    # globを利用してサブディレクトリまでファイルパスを取得する\n","    for path in glob.glob(target_path):\n","        path_list.append(path)\n","\n","    return path_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvYVAA4n-FiM"},"source":["# 良品と不良品の画像のDatasetを作成する\n","class HymenopteraDataset(data.Dataset):\n","    \"\"\"\n","    良否と不良品の画像のDatasetクラス。PyTorchのDatasetクラスを継承。\n","\n","    Attributes\n","    ----------\n","    file_list : リスト\n","        画像のパスを格納したリスト\n","    transform : object\n","        前処理クラスのインスタンス\n","    phase : 'train' or 'test'\n","        学習か予測かを設定する。\n","    \"\"\"\n","\n","    def __init__(self, file_list, transform=None, phase='train'):\n","        self.file_list = file_list  # ファイルパスのリスト\n","        self.transform = transform  # 前処理クラスのインスタンス\n","        self.phase = phase  # train or valの指定\n","\n","    def __len__(self):\n","        '''画像の枚数を返す'''\n","        return len(self.file_list)\n","\n","    def __getitem__(self, index):\n","        '''\n","        前処理をした画像のTensor形式のデータとラベルを取得\n","        '''\n","\n","        # index番目の画像をロード\n","        img_path = self.file_list[index]\n","        img = Image.open(img_path)  # [高さ][幅][色RGB]\n","\n","        # 画像の前処理を実施\n","        img_transformed = self.transform(\n","            img, self.phase)  # torch.Size([3, 224, 224])\n","\n","        # 画像のラベルをファイル名から抜き出す\n","        if self.phase == \"train\":\n","            if 'regular' in img_path:\n","                label = 0\n","            else:\n","                label = 1\n","        elif self.phase == \"val\":\n","            if 'regular' in img_path:\n","                label = 0\n","            else:\n","                label = 1\n","        else:\n","            label = '0'\n","        \n","        return img_transformed, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJ8p1q_T9HNc"},"source":["# 良品と不良品の画像へのファイルパスのリストを作成する\n","train_list = make_datapath_list(phase=\"train\")\n","val_list = make_datapath_list(phase=\"val\")\n","test_list = make_datapath_list(phase=\"test\")\n","\n","# Datasetを作成する\n","size = 224\n","mean = (0.485, 0.456, 0.406)\n","std = (0.229, 0.224, 0.225)\n","train_dataset = HymenopteraDataset(\n","    file_list=train_list, transform=ImageTransform(size, mean, std), phase='train')\n","\n","val_dataset = HymenopteraDataset(\n","    file_list=train_list, transform=ImageTransform(size, mean, std), phase='val')\n","\n","test_dataset = HymenopteraDataset(\n","    file_list=test_list, transform=ImageTransform(size, mean, std), phase='test')\n","\n","# DataLoaderを作成する\n","batch_size = 32\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True)\n","\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=batch_size, shuffle=False)\n","\n","test_dataloader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","# 辞書オブジェクトにまとめる\n","dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader, \"test\": test_dataloader}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UJtID_aT9HNm"},"source":["# ネットワークモデルの作成"]},{"cell_type":"code","metadata":{"id":"soAggp-S9HNn"},"source":["# 学習済みのVGG-16モデルをロード\n","\n","# VGG-16モデルのインスタンスを生成\n","use_pretrained = True  # 学習済みのパラメータを使用\n","net = models.vgg16(pretrained=use_pretrained)\n","\n","# VGG16の最後の層の4096の入力を、良品と不良品の2つを出力する層に変更する\n","net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n","\n","# 訓練モードに設定\n","net.train()\n","\n","print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2WqhZE5S9HNy"},"source":["# 損失関数を定義"]},{"cell_type":"code","metadata":{"id":"LtbUHve99HN0"},"source":["# 損失関数の設定\n","criterion = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnIIOYHL9HN9"},"source":["# 最適化手法を設定"]},{"cell_type":"code","metadata":{"id":"e1LXAhZrm8ez"},"source":["#　モデルの全体像を表示\n","print(net)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o6jFWUhk9HN_"},"source":["# 学習済みモデルのパラメータのうち、再学習（転移学習）させるパラメータを、\n","# 変数params_to_updateの1～3に格納する\n","\n","params_to_update_1 = []\n","params_to_update_2 = []\n","params_to_update_3 = []\n","\n","# 学習させる層のパラメータ名を指定\n","update_param_names_1 = [\"features\"]\n","update_param_names_2 = [\"classifier.0.weight\",\n","                        \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n","update_param_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n","\n","# パラメータごとに各リストに格納する\n","for name, param in net.named_parameters():\n","    if update_param_names_1[0] in name:\n","        param.requires_grad = True\n","        params_to_update_1.append(param)\n","        print(\"params_to_update_1に格納：\", name)\n","\n","    elif name in update_param_names_2:\n","        param.requires_grad = True\n","        params_to_update_2.append(param)\n","        print(\"params_to_update_2に格納：\", name)\n","\n","    elif name in update_param_names_3:\n","        param.requires_grad = True\n","        params_to_update_3.append(param)\n","        print(\"params_to_update_3に格納：\", name)\n","\n","    else:\n","        param.requires_grad = False\n","        print(\"勾配計算なし。学習しない：\", name)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5uj0wXWo9HOE"},"source":["# それぞれのパラメータにつき、最適化手法の設定\n","optimizer = optim.SGD([\n","    {'params': params_to_update_1, 'lr': 1e-4},\n","    {'params': params_to_update_2, 'lr': 5e-4},\n","    {'params': params_to_update_3, 'lr': 1e-3}\n","], momentum=0.9)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bWW8_uhC9HOK"},"source":["# 学習・検証を実施"]},{"cell_type":"code","metadata":{"id":"n6S3Eu1eSEGO"},"source":["!mkdir ./weights/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0JkhSyqr9HOM"},"source":["# モデルを学習させる関数を作成\n","def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n","\n","    # 初期設定\n","    # GPUが使えるかを確認\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    print(\"使用デバイス：\", device)\n","\n","    # ネットワークをGPUへ\n","    net.to(device)\n","\n","    # ネットワークがある程度固定であれば、高速化させる\n","    torch.backends.cudnn.benchmark = True\n","    max_acc = 0\n","    acc_list =[]\n","    # epochのループ\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n","        print('-------------')\n","\n","        # epochごとの訓練と検証のループ\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                net.train()  # モデルを訓練モードに\n","            else:\n","                net.eval()   # モデルを検証モードに\n","\n","            epoch_loss = 0.0  # epochの損失和\n","            epoch_corrects = 0  # epochの正解数\n","\n","            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n","            if (epoch == 0) and (phase == 'train'):\n","                continue\n","\n","            # データローダーからミニバッチを取り出すループ\n","            for inputs, labels in tqdm(dataloaders_dict[phase]):\n","\n","                # GPUが使えるならGPUにデータを送る\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # optimizerを初期化\n","                optimizer.zero_grad()\n","\n","                # 順伝搬（forward）計算\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = net(inputs)\n","                    loss = criterion(outputs, labels)  # 損失を計算\n","                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n","\n","                    # 訓練時はバックプロパゲーション\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                    # 結果の計算\n","                    epoch_loss += loss.item() * inputs.size(0)  # lossの合計を更新\n","                    # 正解数の合計を更新\n","                    epoch_corrects += torch.sum(preds == labels.data)\n","\n","            # epochごとのlossと正解率を表示\n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_acc = epoch_corrects.double(\n","            ) / len(dataloaders_dict[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","            acc_list.append((epoch,epoch_acc))\n","            # PyTorchのネットワークパラメータの保存\n","            if (phase == 'val') and (epoch_acc > max_acc):\n","              !rm save_path\n","              save_path = f'./weights/{epoch_acc}_ep{epoch}_fine_tuning-vgg16.pth'\n","              torch.save(net.state_dict(), save_path)\n","    return acc_list,save_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bksfGb2P9HOT"},"source":["# 学習・検証を実行する\n","num_epochs = N_EPOCHS\n","acc_list,save_path = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OhUckjmh9HOa"},"source":["# 学習したネットワークを保存・ロード"]},{"cell_type":"code","metadata":{"id":"3X4d6oPU9HOh"},"source":["# PyTorchのネットワークパラメータのロード\n","load_path = save_path\n","load_weights = torch.load(load_path)\n","net.load_state_dict(load_weights)\n","\n","# GPU上で保存された重みをCPU上でロードする場合\n","#load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\n","#net.load_state_dict(load_weights)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ku-73XWXeog_"},"source":["# 提出データの作成"]},{"cell_type":"code","metadata":{"id":"J2JPZSEQ3Kt0"},"source":["# テストデータから予測を作成する関数\n","def pred_model(net, dataloaders_dict, criterion, optimizer):\n","  phase = 'test'\n","  net.eval()   # モデルを検証モードに\n","\n","  # 提出データ作成用の入れ物を作成\n","  subT = torch.randn(1)\n","\n","  # データローダーからミニバッチを取り出すループ\n","  for inputs, labels in tqdm(dataloaders_dict[phase]):\n","    # optimizerを初期化\n","    optimizer.zero_grad()\n","    #学習したモデルで、予測を実施\n","    outputs = net(inputs)\n","    _, preds = torch.max(outputs, 1)  # ラベルを予測\n","    #print(subT.shape,preds.shape)\n","    subT = torch.cat([subT,preds])\n","  #print(subT.shape)\n","  return subT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"je0921CnvMvZ"},"source":["#　テストデータから予測の実行\n","sub = pred_model(net, dataloaders_dict, criterion, optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aMHgCcL0yOh1"},"source":["#予測結果をCPU上のnumpy配列に変換\n","xnumpy = sub.to('cpu').detach().numpy().copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"00DMnW6YySR-"},"source":["import pandas as pd \n","sublabel = pd.DataFrame(xnumpy[1:]) #　予測値をデータフレームに格納\n","sublabel.columns = ['sub'] #　列名を提出で指定されたsubにする\n","sublabel = sublabel.astype(int) # 予測値を整数（０か１）に変換\n","\n","subdf = pd.DataFrame(test_list) # testデータのファイルリストを取得\n","filelist = subdf[0].str.split('/',expand=True) #　ファイル名だけ抽出\n","\n","# ファイル名のリストと、予測値を結合\n","subfin = pd.concat([filelist,sublabel],axis=1) \n","sortedsub=subfin.sort_values(2) #　ファイル名順に並べ替え\n","lastsub = sortedsub[[2,'sub']] #　必要な列だけに絞り込み\n","\n","#提出ファイルを保存\n","lastsub.to_csv(f'{outputpath}/001-submit.tsv',header=False, index=False, sep='\\t') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aGsNxlbByR3n"},"source":["lastsub"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GLD73ekn9HOs"},"source":["以上"]}]}